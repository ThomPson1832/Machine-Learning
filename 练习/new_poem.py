import torch; from transformers import AutoTokenizer, GPT2LMHeadModel, TextGenerationPipeline  
print("=== 新脚本开始执行 ==="); print("1. 正在加载分词器..."); tokenizer = AutoTokenizer.from_pretrained("uer/gpt2-chinese-poem"); print("2. 正在加载模型..."); model = GPT2LMHeadModel.from_pretrained("uer/gpt2-chinese-poem"); print("3. 模型加载成功，开始生成诗歌..."); result = TextGenerationPipeline(model, tokenizer)("[CLS] 万 叠 春 山 积 雨 晴 ,", max_length=60, do_sample=True, temperature=0.7); poem = result[0]['generated_text'].replace("[CLS]", "").strip(); print("\n✅ 生成完成！古诗结果："); print("-" * 60); print(poem); print("-" * 60) 
