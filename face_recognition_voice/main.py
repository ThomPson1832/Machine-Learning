# main.py - ä¸»ç¨‹åºï¼ˆå¢å¼ºç‰ˆè¯­éŸ³æ’­æŠ¥äººè„¸è¯†åˆ«ç³»ç»Ÿï¼‰
import sys
import os
import cv2
import json
import time
import logging
from datetime import datetime
from typing import List, Tuple

from PyQt5.QtWidgets import (
    QApplication, QMainWindow, QPushButton, QLabel, QVBoxLayout, QHBoxLayout,
    QWidget, QInputDialog, QComboBox, QSlider, QGroupBox, QFormLayout,
    QTextEdit, QSplitter, QTabWidget, QMessageBox, QProgressBar
)
from PyQt5.QtCore import Qt, QTimer, pyqtSignal, QThread
from PyQt5.QtGui import QImage, QPixmap, QFont, QPalette, QColor

from face_recognizer import FaceRecognizer
from voice_speaker import VoiceSpeaker

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('face_recognition.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)


class RecognitionThread(QThread):
    """äººè„¸è¯†åˆ«çº¿ç¨‹"""
    recognition_complete = pyqtSignal(list)

    def __init__(self, recognizer, frame):
        super().__init__()
        self.recognizer = recognizer
        self.frame = frame.copy()

    def run(self):
        try:
            results = self.recognizer.recognize(self.frame)
            self.recognition_complete.emit(results)
        except Exception as e:
            logging.error(f"è¯†åˆ«çº¿ç¨‹é”™è¯¯: {e}")
            self.recognition_complete.emit([])


class FaceRecognitionApp(QMainWindow):
    """ä¸»åº”ç”¨ç¨‹åº"""

    def __init__(self):
        super().__init__()
        self.setWindowTitle("ğŸ­ æ™ºèƒ½è¯­éŸ³æ’­æŠ¥äººè„¸è¯†åˆ«ç³»ç»Ÿ")
        self.setGeometry(100, 100, 1400, 900)

        # åˆå§‹åŒ–ç»„ä»¶
        self.recognizer = FaceRecognizer()
        self.speaker = VoiceSpeaker()

        # çŠ¶æ€å˜é‡
        self.is_recognizing = False
        self.is_camera_available = False
        self.last_speak_time = {}
        self.recognition_results = []

        # åŠ è½½é…ç½®
        self.config = self.load_config()
        self.apply_config()

        # åˆå§‹åŒ–UI
        self.init_ui()
        self.init_camera()

        # å®šæ—¶å™¨
        self.timer = QTimer()
        self.timer.timeout.connect(self.process_frame)

        logging.info("åº”ç”¨ç¨‹åºåˆå§‹åŒ–å®Œæˆ")

    def load_config(self):
        """åŠ è½½é…ç½®"""
        try:
            with open("config.json", "r", encoding="utf-8") as f:
                return json.load(f)
        except Exception as e:
            logging.error(f"åŠ è½½é…ç½®å¤±è´¥: {e}")
            return self.get_default_config()

    def get_default_config(self):
        """è·å–é»˜è®¤é…ç½®"""
        return {
            "mode": "å®Œæ•´æ¨¡å¼",
            "volume": 0.8,
            "rate": 150,
            "enable_unknown_alert": True,
            "speak_cooldown": 5,
            "camera_index": 0,
            "face_database": "face_database.json",
            "recognition_threshold": 0.6
        }

    def save_config(self):
        """ä¿å­˜é…ç½®"""
        try:
            with open("config.json", "w", encoding="utf-8") as f:
                json.dump(self.config, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logging.error(f"ä¿å­˜é…ç½®å¤±è´¥: {e}")

    def apply_config(self):
        """åº”ç”¨é…ç½®"""
        # è¯­éŸ³è®¾ç½®
        self.speaker.set_volume(self.config.get('volume', 0.8))
        self.speaker.set_rate(self.config.get('rate', 150))

        # åº”ç”¨è®¾ç½®
        self.speak_cooldown = self.config.get('speak_cooldown', 5)
        self.enable_unknown_alert = self.config.get('enable_unknown_alert', True)
        self.current_mode = self.config.get('mode', 'å®Œæ•´æ¨¡å¼')

    def init_ui(self):
        """åˆå§‹åŒ–ç”¨æˆ·ç•Œé¢"""
        # è®¾ç½®æ ·å¼
        self.setStyleSheet("""
            QMainWindow {
                background-color: #2b2b2b;
                color: white;
            }
            QPushButton {
                background-color: #4CAF50;
                color: white;
                border: none;
                padding: 8px 16px;
                border-radius: 4px;
                font-size: 14px;
            }
            QPushButton:hover {
                background-color: #45a049;
            }
            QPushButton:pressed {
                background-color: #3d8b40;
            }
            QLabel {
                color: white;
                font-size: 14px;
            }
            QComboBox, QSlider {
                background-color: #3c3c3c;
                color: white;
                border: 1px solid #555;
                border-radius: 4px;
            }
            QGroupBox {
                color: #4CAF50;
                font-weight: bold;
                border: 2px solid #4CAF50;
                border-radius: 8px;
                margin-top: 10px;
                padding-top: 10px;
            }
            QTextEdit {
                background-color: #1e1e1e;
                color: #00ff00;
                border: 1px solid #555;
                border-radius: 4px;
                font-family: 'Courier New';
            }
        """)

        # ä¸»å¸ƒå±€
        main_widget = QWidget()
        self.setCentralWidget(main_widget)
        layout = QHBoxLayout(main_widget)

        # å·¦ä¾§è§†é¢‘åŒºåŸŸ
        left_widget = QWidget()
        left_layout = QVBoxLayout(left_widget)

        # è§†é¢‘æ˜¾ç¤º
        self.video_label = QLabel("æ‘„åƒå¤´æœªå¯åŠ¨")
        self.video_label.setAlignment(Qt.AlignCenter)
        self.video_label.setMinimumSize(800, 600)
        self.video_label.setStyleSheet("QLabel { background: black; color: white; font-size: 16px; }")

        # æ§åˆ¶æŒ‰é’®
        control_layout = QHBoxLayout()
        self.recognize_btn = QPushButton("ğŸ§ å¼€å§‹è¯†åˆ«")
        self.capture_btn = QPushButton("ğŸ“¸ é‡‡é›†äººè„¸")
        self.clear_db_btn = QPushButton("ğŸ—‘ï¸ æ¸…ç©ºæ•°æ®åº“")

        control_layout.addWidget(self.recognize_btn)
        control_layout.addWidget(self.capture_btn)
        control_layout.addWidget(self.clear_db_btn)

        # çŠ¶æ€æ˜¾ç¤º
        self.status_label = QLabel("ğŸ”´ ç³»ç»Ÿå°±ç»ª")
        self.status_label.setStyleSheet("QLabel { font-size: 16px; color: #ff6b6b; }")

        left_layout.addWidget(self.video_label)
        left_layout.addLayout(control_layout)
        left_layout.addWidget(self.status_label)

        # å³ä¾§æ§åˆ¶é¢æ¿
        right_widget = QWidget()
        right_layout = QVBoxLayout(right_widget)
        right_layout.setAlignment(Qt.AlignTop)

        # è¯­éŸ³è®¾ç½®ç»„
        voice_group = QGroupBox("ğŸµ è¯­éŸ³è®¾ç½®")
        voice_layout = QFormLayout(voice_group)

        self.mode_combo = QComboBox()
        self.mode_combo.addItems(["ç®€æ´æ¨¡å¼", "å®Œæ•´æ¨¡å¼", "å®‰å…¨æ¨¡å¼", "é™éŸ³æ¨¡å¼"])
        self.mode_combo.setCurrentText(self.current_mode)

        self.volume_slider = QSlider(Qt.Horizontal)
        self.volume_slider.setRange(0, 100)
        self.volume_slider.setValue(int(self.config.get('volume', 0.8) * 100))

        self.rate_slider = QSlider(Qt.Horizontal)
        self.rate_slider.setRange(50, 300)
        self.rate_slider.setValue(self.config.get('rate', 150))

        voice_layout.addRow("æ’­æŠ¥æ¨¡å¼:", self.mode_combo)
        voice_layout.addRow("éŸ³é‡è°ƒèŠ‚:", self.volume_slider)
        voice_layout.addRow("è¯­é€Ÿè°ƒèŠ‚:", self.rate_slider)

        # è¯†åˆ«è®¾ç½®ç»„
        recog_group = QGroupBox("ğŸ” è¯†åˆ«è®¾ç½®")
        recog_layout = QFormLayout(recog_group)

        self.threshold_slider = QSlider(Qt.Horizontal)
        self.threshold_slider.setRange(1, 10)
        self.threshold_slider.setValue(int(self.config.get('recognition_threshold', 0.6) * 10))

        self.cooldown_slider = QSlider(Qt.Horizontal)
        self.cooldown_slider.setRange(1, 30)
        self.cooldown_slider.setValue(self.config.get('speak_cooldown', 5))

        recog_layout.addRow("è¯†åˆ«é˜ˆå€¼:", self.threshold_slider)
        recog_layout.addRow("æ’­æŠ¥é—´éš”:", self.cooldown_slider)

        # æ—¥å¿—æ˜¾ç¤º
        log_group = QGroupBox("ğŸ“ ç³»ç»Ÿæ—¥å¿—")
        log_layout = QVBoxLayout(log_group)
        self.log_text = QTextEdit()
        self.log_text.setMaximumHeight(200)
        self.log_text.setReadOnly(True)
        log_layout.addWidget(self.log_text)

        # æ•°æ®åº“ä¿¡æ¯
        db_group = QGroupBox("ğŸ’¾ æ•°æ®åº“ä¿¡æ¯")
        db_layout = QVBoxLayout(db_group)
        self.db_info_label = QLabel("åŠ è½½ä¸­...")
        db_layout.addWidget(self.db_info_label)

        right_layout.addWidget(voice_group)
        right_layout.addWidget(recog_group)
        right_layout.addWidget(db_group)
        right_layout.addWidget(log_group)

        # åˆ†å‰²å¸ƒå±€
        splitter = QSplitter(Qt.Horizontal)
        splitter.addWidget(left_widget)
        splitter.addWidget(right_widget)
        splitter.setSizes([800, 400])

        layout.addWidget(splitter)

        # è¿æ¥ä¿¡å·
        self.connect_signals()

        # æ›´æ–°æ•°æ®åº“ä¿¡æ¯
        self.update_database_info()

    def connect_signals(self):
        """è¿æ¥ä¿¡å·æ§½"""
        self.recognize_btn.clicked.connect(self.toggle_recognition)
        self.capture_btn.clicked.connect(self.capture_face)
        self.clear_db_btn.clicked.connect(self.clear_database)

        self.mode_combo.currentTextChanged.connect(self.on_mode_change)
        self.volume_slider.valueChanged.connect(self.on_volume_change)
        self.rate_slider.valueChanged.connect(self.on_rate_change)
        self.threshold_slider.valueChanged.connect(self.on_threshold_change)
        self.cooldown_slider.valueChanged.connect(self.on_cooldown_change)

    def init_camera(self):
        """åˆå§‹åŒ–æ‘„åƒå¤´"""
        try:
            camera_index = self.config.get('camera_index', 0)
            self.cap = cv2.VideoCapture(camera_index)

            if self.cap.isOpened():
                self.is_camera_available = True
                self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
                self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
                self.log_message("âœ… æ‘„åƒå¤´åˆå§‹åŒ–æˆåŠŸ")
            else:
                self.is_camera_available = False
                self.log_message("âŒ æ‘„åƒå¤´åˆå§‹åŒ–å¤±è´¥")

        except Exception as e:
            self.is_camera_available = False
            self.log_message(f"âŒ æ‘„åƒå¤´åˆå§‹åŒ–é”™è¯¯: {e}")

    def toggle_recognition(self):
        """åˆ‡æ¢è¯†åˆ«çŠ¶æ€"""
        if not self.is_camera_available:
            QMessageBox.warning(self, "è­¦å‘Š", "æ‘„åƒå¤´ä¸å¯ç”¨ï¼Œè¯·æ£€æŸ¥è¿æ¥")
            return

        if not self.is_recognizing:
            # å¼€å§‹è¯†åˆ«
            self.is_recognizing = True
            self.recognize_btn.setText("ğŸ›‘ åœæ­¢è¯†åˆ«")
            self.recognize_btn.setStyleSheet("background-color: #ff6b6b;")
            self.status_label.setText("ğŸŸ¢ è¯†åˆ«ä¸­...")
            self.status_label.setStyleSheet("QLabel { color: #4CAF50; }")
            self.timer.start(100)  # 10 FPS
            self.log_message("ğŸ¯ å¼€å§‹äººè„¸è¯†åˆ«")
        else:
            # åœæ­¢è¯†åˆ«
            self.is_recognizing = False
            self.recognize_btn.setText("ğŸ§ å¼€å§‹è¯†åˆ«")
            self.recognize_btn.setStyleSheet("background-color: #4CAF50;")
            self.status_label.setText("ğŸ”´ è¯†åˆ«å·²åœæ­¢")
            self.status_label.setStyleSheet("QLabel { color: #ff6b6b; }")
            self.timer.stop()
            self.log_message("â¹ï¸ åœæ­¢äººè„¸è¯†åˆ«")

    def process_frame(self):
        """å¤„ç†è§†é¢‘å¸§"""
        if not self.is_camera_available:
            return

        ret, frame = self.cap.read()
        if not ret:
            self.log_message("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
            return

        # æ°´å¹³ç¿»è½¬
        frame = cv2.flip(frame, 1)

        if self.is_recognizing:
            # åœ¨å­çº¿ç¨‹ä¸­è¿›è¡Œè¯†åˆ«
            self.recognition_thread = RecognitionThread(self.recognizer, frame)
            self.recognition_thread.recognition_complete.connect(self.on_recognition_complete)
            self.recognition_thread.start()
        else:
            # åªæ˜¾ç¤ºç”»é¢
            self.display_frame(frame)

    def on_recognition_complete(self, results):
        """è¯†åˆ«å®Œæˆå›è°ƒ"""
        self.recognition_results = results

        # è·å–å½“å‰å¸§å¹¶æ˜¾ç¤ºç»“æœ
        ret, frame = self.cap.read()
        if ret:
            frame = cv2.flip(frame, 1)
            self.display_frame(frame, results)
            self.handle_voice_announce(results)

    def display_frame(self, frame, results=None):
        """æ˜¾ç¤ºè§†é¢‘å¸§å’Œè¯†åˆ«ç»“æœ"""
        display_frame = frame.copy()

        if results:
            known_count = 0
            unknown_count = 0

            for name, bbox, confidence in results:
                x, y, w, h = bbox

                # è®¾ç½®é¢œè‰²
                if name == "æœªçŸ¥äººå‘˜":
                    color = (0, 0, 255)  # çº¢è‰²
                    unknown_count += 1
                else:
                    color = (0, 255, 0)  # ç»¿è‰²
                    known_count += 1

                # ç»˜åˆ¶çŸ©å½¢
                cv2.rectangle(display_frame, (x, y), (x + w, y + h), color, 2)

                # ç»˜åˆ¶æ ‡ç­¾
                label = f"{name} ({confidence:.2f})"
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                cv2.rectangle(display_frame, (x, y - label_size[1] - 10),
                              (x + label_size[0], y), color, -1)
                cv2.putText(display_frame, label, (x, y - 5),
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)

            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats_text = f"å·²çŸ¥: {known_count} | æœªçŸ¥: {unknown_count}"
            cv2.putText(display_frame, stats_text, (10, 30),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)

        # è½¬æ¢ä¸ºQtæ ¼å¼æ˜¾ç¤º
        rgb_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
        h, w, ch = rgb_frame.shape
        bytes_per_line = ch * w
        qt_image = QImage(rgb_frame.data, w, h, bytes_per_line, QImage.Format_RGB888)
        self.video_label.setPixmap(QPixmap.fromImage(qt_image).scaled(
            self.video_label.width(), self.video_label.height(),
            Qt.KeepAspectRatio, Qt.SmoothTransformation
        ))

    def handle_voice_announce(self, results):
        """å¤„ç†è¯­éŸ³æ’­æŠ¥"""
        if not results or self.current_mode == "é™éŸ³æ¨¡å¼":
            return

        current_time = time.time()
        names_to_speak = []

        for name, _, confidence in results:
            # æ£€æŸ¥å†·å´æ—¶é—´
            last_time = self.last_speak_time.get(name, 0)
            if current_time - last_time > self.speak_cooldown:
                names_to_speak.append(name)
                self.last_speak_time[name] = current_time

        if names_to_speak:
            # è¿‡æ»¤æœªçŸ¥äººå‘˜ï¼ˆæ ¹æ®é…ç½®ï¼‰
            known_names = [name for name in names_to_speak if name != "æœªçŸ¥äººå‘˜"]
            unknown_names = [name for name in names_to_speak if name == "æœªçŸ¥äººå‘˜"]

            # æ„å»ºæ’­æŠ¥åˆ—è¡¨
            speak_names = known_names
            if self.enable_unknown_alert and unknown_names:
                speak_names.extend(unknown_names)

            if speak_names:
                self.speaker.speak_face_result(speak_names, self.current_mode, self.enable_unknown_alert)
                self.log_message(f"ğŸµ æ’­æŠ¥: {', '.join(speak_names)}")

    def capture_face(self):
        """é‡‡é›†äººè„¸"""
        if not self.is_camera_available:
            QMessageBox.warning(self, "è­¦å‘Š", "æ‘„åƒå¤´ä¸å¯ç”¨")
            return

        ret, frame = self.cap.read()
        if not ret:
            QMessageBox.warning(self, "é”™è¯¯", "æ— æ³•è·å–æ‘„åƒå¤´ç”»é¢")
            return

        frame = cv2.flip(frame, 1)

        # æ£€æµ‹æ˜¯å¦æœ‰äººè„¸
        faces = self.recognizer.detect_faces(frame)
        if len(faces) == 0:
            QMessageBox.warning(self, "æç¤º", "æœªæ£€æµ‹åˆ°äººè„¸ï¼Œè¯·è°ƒæ•´ä½ç½®")
            return
        elif len(faces) > 1:
            QMessageBox.warning(self, "æç¤º", "æ£€æµ‹åˆ°å¤šä¸ªäººè„¸ï¼Œè¯·ç¡®ä¿åªæœ‰ä¸€ä¸ªäººè„¸åœ¨ç”»é¢ä¸­")
            return

        # è¾“å…¥å§“å
        name, ok = QInputDialog.getText(self, "é‡‡é›†äººè„¸", "è¯·è¾“å…¥å§“å:")
        if ok and name.strip():
            success, message = self.recognizer.capture_face(frame, name.strip())
            if success:
                QMessageBox.information(self, "æˆåŠŸ", message)
                self.log_message(f"âœ… {message}")
                self.update_database_info()
            else:
                QMessageBox.warning(self, "å¤±è´¥", message)
                self.log_message(f"âŒ {message}")

    def clear_database(self):
        """æ¸…ç©ºæ•°æ®åº“"""
        reply = QMessageBox.question(self, "ç¡®è®¤", "ç¡®å®šè¦æ¸…ç©ºæ‰€æœ‰äººè„¸æ•°æ®å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ¢å¤ï¼",
                                     QMessageBox.Yes | QMessageBox.No)
        if reply == QMessageBox.Yes:
            self.recognizer.face_database = {}
            self.recognizer.save_face_database()
            self.update_database_info()
            self.log_message("ğŸ—‘ï¸ äººè„¸æ•°æ®åº“å·²æ¸…ç©º")
            QMessageBox.information(self, "å®Œæˆ", "æ•°æ®åº“å·²æ¸…ç©º")

    def update_database_info(self):
        """æ›´æ–°æ•°æ®åº“ä¿¡æ¯"""
        db_info = self.recognizer.get_database_info()
        info_text = f"""
        æ€»äººæ•°: {db_info['total_faces']}
        æ³¨å†Œåå•: {', '.join(db_info['names']) if db_info['names'] else 'æ— '}
        æœ€åæ›´æ–°: {db_info['last_update']}
        """
        self.db_info_label.setText(info_text)

    def log_message(self, message):
        """è®°å½•æ—¥å¿—æ¶ˆæ¯"""
        timestamp = datetime.now().strftime("%H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self.log_text.append(log_entry)

        # è‡ªåŠ¨æ»šåŠ¨åˆ°åº•éƒ¨
        scrollbar = self.log_text.verticalScrollBar()
        scrollbar.setValue(scrollbar.maximum())

        logging.info(message)

    # é…ç½®å˜æ›´å¤„ç†
    def on_mode_change(self, mode):
        self.current_mode = mode
        self.config['mode'] = mode
        self.save_config()
        self.log_message(f"ğŸ”§ åˆ‡æ¢æ¨¡å¼: {mode}")

    def on_volume_change(self, value):
        volume = value / 100.0
        self.speaker.set_volume(volume)
        self.config['volume'] = volume
        self.save_config()

    def on_rate_change(self, value):
        self.speaker.set_rate(value)
        self.config['rate'] = value
        self.save_config()

    def on_threshold_change(self, value):
        threshold = value / 10.0
        self.recognizer.recognition_threshold = threshold
        self.config['recognition_threshold'] = threshold
        self.save_config()
        self.log_message(f"ğŸ”§ è¯†åˆ«é˜ˆå€¼è°ƒæ•´ä¸º: {threshold}")

    def on_cooldown_change(self, value):
        self.speak_cooldown = value
        self.config['speak_cooldown'] = value
        self.save_config()
        self.log_message(f"ğŸ”§ æ’­æŠ¥é—´éš”è°ƒæ•´ä¸º: {value}ç§’")

    def closeEvent(self, event):
        """å…³é—­äº‹ä»¶"""
        self.timer.stop()
        if hasattr(self, 'cap'):
            self.cap.release()
        self.speaker.stop()
        self.save_config()
        self.log_message("ğŸ”š åº”ç”¨ç¨‹åºå·²é€€å‡º")
        event.accept()


if __name__ == "__main__":
    app = QApplication(sys.argv)

    # è®¾ç½®åº”ç”¨ç¨‹åºå±æ€§
    app.setApplicationName("æ™ºèƒ½è¯­éŸ³æ’­æŠ¥äººè„¸è¯†åˆ«ç³»ç»Ÿ")
    app.setApplicationVersion("2.0.0")

    window = FaceRecognitionApp()
    window.show()

    sys.exit(app.exec_())